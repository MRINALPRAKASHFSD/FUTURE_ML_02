{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Install and import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ],
      "metadata": {
        "id": "RKXtQagQ3W5U"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Upload your dataset (CSV file)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # Upload your 'stock_data.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "gOYDtNbR4Nca",
        "outputId": "7e053a5c-8e7b-4559-8a4a-602b363ccc18"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0ecbbab5-4c86-4bc9-88d4-4626f6c0d337\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0ecbbab5-4c86-4bc9-88d4-4626f6c0d337\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving symbols_valid_meta.csv to symbols_valid_meta.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Load the dataset\n",
        "df = pd.read_csv('symbols_valid_meta.csv')\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsnrjO7C4QSC",
        "outputId": "0676dc7b-cf91-4f35-d23d-12551c1cb747"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Nasdaq Traded Symbol                                      Security Name  \\\n",
            "0             Y      A            Agilent Technologies, Inc. Common Stock   \n",
            "1             Y     AA                    Alcoa Corporation Common Stock    \n",
            "2             Y   AAAU                       Perth Mint Physical Gold ETF   \n",
            "3             Y   AACG  ATA Creativity Global - American Depositary Sh...   \n",
            "4             Y   AADR                AdvisorShares Dorsey Wright ADR ETF   \n",
            "\n",
            "  Listing Exchange Market Category ETF  Round Lot Size Test Issue  \\\n",
            "0                N                   N           100.0          N   \n",
            "1                N                   N           100.0          N   \n",
            "2                P                   Y           100.0          N   \n",
            "3                Q               G   N           100.0          N   \n",
            "4                P                   Y           100.0          N   \n",
            "\n",
            "  Financial Status CQS Symbol NASDAQ Symbol NextShares  \n",
            "0              NaN          A             A          N  \n",
            "1              NaN         AA            AA          N  \n",
            "2              NaN       AAAU          AAAU          N  \n",
            "3                N        NaN          AACG          N  \n",
            "4              NaN       AADR          AADR          N  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('symbols_valid_meta.csv', header=None)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAWViFXm5kuD",
        "outputId": "045d4b09-d53c-4521-d855-1cbe83e74010"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              0       1                                                  2   \\\n",
            "0  Nasdaq Traded  Symbol                                      Security Name   \n",
            "1              Y       A            Agilent Technologies, Inc. Common Stock   \n",
            "2              Y      AA                    Alcoa Corporation Common Stock    \n",
            "3              Y    AAAU                       Perth Mint Physical Gold ETF   \n",
            "4              Y    AACG  ATA Creativity Global - American Depositary Sh...   \n",
            "\n",
            "                 3                4    5               6           7   \\\n",
            "0  Listing Exchange  Market Category  ETF  Round Lot Size  Test Issue   \n",
            "1                 N                     N           100.0           N   \n",
            "2                 N                     N           100.0           N   \n",
            "3                 P                     Y           100.0           N   \n",
            "4                 Q                G    N           100.0           N   \n",
            "\n",
            "                 8           9              10          11  \n",
            "0  Financial Status  CQS Symbol  NASDAQ Symbol  NextShares  \n",
            "1               NaN           A              A           N  \n",
            "2               NaN          AA             AA           N  \n",
            "3               NaN        AAAU           AAAU           N  \n",
            "4                 N         NaN           AACG           N  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n",
        "print(len(df.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlUhDZsh59dA",
        "outputId": "2ef81198-c884-4680-df50-56c0cf0e9776"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], dtype='int64')\n",
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = ['col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'col7', 'col8', 'col9', 'col10', 'col11', 'col12']"
      ],
      "metadata": {
        "id": "JVyiog966HMS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkEZSz9L6dWK",
        "outputId": "64489ef6-f15a-457e-d3e5-883706a05cb0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'col7', 'col8', 'col9',\n",
            "       'col10', 'col11', 'col12'],\n",
            "      dtype='object')\n",
            "            col1    col2                                               col3  \\\n",
            "0  Nasdaq Traded  Symbol                                      Security Name   \n",
            "1              Y       A            Agilent Technologies, Inc. Common Stock   \n",
            "2              Y      AA                    Alcoa Corporation Common Stock    \n",
            "3              Y    AAAU                       Perth Mint Physical Gold ETF   \n",
            "4              Y    AACG  ATA Creativity Global - American Depositary Sh...   \n",
            "\n",
            "               col4             col5 col6            col7        col8  \\\n",
            "0  Listing Exchange  Market Category  ETF  Round Lot Size  Test Issue   \n",
            "1                 N                     N           100.0           N   \n",
            "2                 N                     N           100.0           N   \n",
            "3                 P                     Y           100.0           N   \n",
            "4                 Q                G    N           100.0           N   \n",
            "\n",
            "               col9       col10          col11       col12  \n",
            "0  Financial Status  CQS Symbol  NASDAQ Symbol  NextShares  \n",
            "1               NaN           A              A           N  \n",
            "2               NaN          AA             AA           N  \n",
            "3               NaN        AAAU           AAAU           N  \n",
            "4                 N         NaN           AACG           N  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hc6zq357Tsp",
        "outputId": "c377b3bd-d953-4b4d-ad1e-9e7910e47627"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'col7', 'col8', 'col9', 'col10', 'col11', 'col12']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "['CLOSE ', 'OPEN', 'HIGH', 'LOW', 'VOLUME']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2j5ZsbY7VFC",
        "outputId": "1430f8cd-ca8d-4c5a-f29a-69c22b05e076"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CLOSE ', 'OPEN', 'HIGH', 'LOW', 'VOLUME']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = df.columns.str.strip()\n",
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPbtl3Nj7YBT",
        "outputId": "c8dc442b-9e4f-464f-dbd8-187d390df442"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'col7', 'col8', 'col9', 'col10', 'col11', 'col12']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Load the dataset and assign column names\n",
        "df = pd.read_csv('symbols_valid_meta.csv', header=None)\n",
        "\n",
        "# Assuming the data is in the order implied by the subsequent usage (CLOSE, OPEN, etc.)\n",
        "# You might need to adjust these column names based on the actual data in your CSV.\n",
        "# Let's assume the relevant columns are at the end, matching the number of columns assigned previously (12)\n",
        "# and that CLOSE is one of them. You need to identify which column index corresponds to 'CLOSE'.\n",
        "# For this fix, let's assume 'CLOSE' is the 10th column (index 9), 'OPEN' is 9th (index 8), etc.,\n",
        "# and the first few columns are metadata we can give generic names or drop if not needed.\n",
        "\n",
        "# It's crucial to know the actual column order in your CSV to name them correctly.\n",
        "# If you are unsure, print the head of the dataframe after loading with header=None\n",
        "# and manually identify which column index corresponds to 'CLOSE'.\n",
        "\n",
        "# Let's rename the columns assuming the structure matches a typical stock data format\n",
        "# with identifier columns followed by price/volume data.\n",
        "# This is an assumption based on the previous code. Adjust indices/names as needed.\n",
        "new_column_names = [\n",
        "    'symbol', 'exchange', 'name', 'sector', 'industry', # Example metadata columns\n",
        "    'col6', 'col7', # Example filler columns if needed\n",
        "    'OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME' # Stock data columns\n",
        "]\n",
        "\n",
        "# Ensure the number of new column names matches the number of columns in the DataFrame\n",
        "if len(new_column_names) == len(df.columns):\n",
        "    df.columns = new_column_names\n",
        "else:\n",
        "    # If the number of columns doesn't match, you need to inspect your CSV\n",
        "    # and define the correct list of column names.\n",
        "    print(f\"Warning: Number of columns in CSV ({len(df.columns)}) does not match the number of provided column names ({len(new_column_names)}).\")\n",
        "    print(\"Please adjust the 'new_column_names' list based on your CSV content.\")\n",
        "    # Fallback to generic names if column count doesn't match\n",
        "    df.columns = [f'col{i+1}' for i in range(len(df.columns))]\n",
        "\n",
        "print(df.head())\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# %%\n",
        "# The following cell attempted to set columns using a list - this is not needed anymore\n",
        "# since we set them correctly above.\n",
        "# ['CLOSE ', 'OPEN', 'HIGH', 'LOW', 'VOLUME'] # This line was just a list definition, not assignment\n",
        "\n",
        "# %%\n",
        "# This cell is now potentially redundant if column names are set correctly above.\n",
        "# However, let's keep the stripping just in case there are leading/trailing spaces\n",
        "# in the actual column names we assigned, though less likely with a direct list assignment.\n",
        "df.columns = df.columns.str.strip()\n",
        "print(df.columns.tolist())\n",
        "\n",
        "# %%\n",
        "# Cell with the error: Now 'CLOSE' should exist\n",
        "df['Prev_Close'] = df['CLOSE'].shift(1)\n",
        "df = df.dropna()\n",
        "X = df[['Prev_Close']]\n",
        "y = df['CLOSE']\n",
        "\n",
        "print(\"\\nDataFrame after adding Prev_Close and dropping NaNs:\")\n",
        "print(df.head())\n",
        "print(\"\\nShape of X:\", X.shape)\n",
        "print(\"Shape of y:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B9O1Yqb777h",
        "outputId": "ef2b4137-c93a-423e-e6bb-812e34d53d1d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          symbol exchange                                               name  \\\n",
            "0  Nasdaq Traded   Symbol                                      Security Name   \n",
            "1              Y        A            Agilent Technologies, Inc. Common Stock   \n",
            "2              Y       AA                    Alcoa Corporation Common Stock    \n",
            "3              Y     AAAU                       Perth Mint Physical Gold ETF   \n",
            "4              Y     AACG  ATA Creativity Global - American Depositary Sh...   \n",
            "\n",
            "             sector         industry col6            col7        OPEN  \\\n",
            "0  Listing Exchange  Market Category  ETF  Round Lot Size  Test Issue   \n",
            "1                 N                     N           100.0           N   \n",
            "2                 N                     N           100.0           N   \n",
            "3                 P                     Y           100.0           N   \n",
            "4                 Q                G    N           100.0           N   \n",
            "\n",
            "               HIGH         LOW          CLOSE      VOLUME  \n",
            "0  Financial Status  CQS Symbol  NASDAQ Symbol  NextShares  \n",
            "1               NaN           A              A           N  \n",
            "2               NaN          AA             AA           N  \n",
            "3               NaN        AAAU           AAAU           N  \n",
            "4                 N         NaN           AACG           N  \n",
            "['symbol', 'exchange', 'name', 'sector', 'industry', 'col6', 'col7', 'OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME']\n",
            "['symbol', 'exchange', 'name', 'sector', 'industry', 'col6', 'col7', 'OPEN', 'HIGH', 'LOW', 'CLOSE', 'VOLUME']\n",
            "\n",
            "DataFrame after adding Prev_Close and dropping NaNs:\n",
            "Empty DataFrame\n",
            "Columns: [symbol, exchange, name, sector, industry, col6, col7, OPEN, HIGH, LOW, CLOSE, VOLUME, Prev_Close]\n",
            "Index: []\n",
            "\n",
            "Shape of X: (0, 1)\n",
            "Shape of y: (0,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell with the error: Now 'CLOSE' should exist\n",
        "df['Prev_Close'] = df['CLOSE'].shift(1)\n",
        "\n",
        "# Add this line to check the shape before dropping NaNs\n",
        "print(\"\\nShape of DataFrame before dropping NaNs:\", df.shape)\n",
        "\n",
        "df = df.dropna()\n",
        "X = df[['Prev_Close']]\n",
        "y = df['CLOSE']\n",
        "\n",
        "print(\"\\nDataFrame after adding Prev_Close and dropping NaNs:\")\n",
        "print(df.head())\n",
        "print(\"\\nShape of X:\", X.shape)\n",
        "print(\"Shape of y:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Deed7vq8LQK",
        "outputId": "fa763ccd-73bd-482b-8d71-6a72b170bc9e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shape of DataFrame before dropping NaNs: (0, 13)\n",
            "\n",
            "DataFrame after adding Prev_Close and dropping NaNs:\n",
            "Empty DataFrame\n",
            "Columns: [symbol, exchange, name, sector, industry, col6, col7, OPEN, HIGH, LOW, CLOSE, VOLUME, Prev_Close]\n",
            "Index: []\n",
            "\n",
            "Shape of X: (0, 1)\n",
            "Shape of y: (0,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell with the error: Now 'CLOSE' should exist\n",
        "# Add a check for the existence of the 'CLOSE' column\n",
        "if 'CLOSE' not in df.columns:\n",
        "    print(\"Error: 'CLOSE' column not found in the DataFrame.\")\n",
        "    # You need to correct the column renaming step above based on your CSV content.\n",
        "    # For now, let's stop execution or handle this case appropriately.\n",
        "    # For demonstration, we'll proceed, but this is a critical issue.\n",
        "    # You might want to add sys.exit() or raise an error here in a real script.\n",
        "    pass # Allowing execution to continue for demonstration of the next steps\n",
        "\n",
        "# Check the shape and content of the DataFrame before adding 'Prev_Close'\n",
        "print(\"\\nDataFrame shape before adding Prev_Close:\", df.shape)\n",
        "print(\"Data types before adding Prev_Close:\\n\", df.dtypes)\n",
        "print(\"\\nFirst few rows before adding Prev_Close:\")\n",
        "print(df.head())\n",
        "\n",
        "# Add 'Prev_Close' column\n",
        "if 'CLOSE' in df.columns:\n",
        "    # Attempt to convert 'CLOSE' to numeric, coercing errors to NaN\n",
        "    df['CLOSE'] = pd.to_numeric(df['CLOSE'], errors='coerce')\n",
        "    df['Prev_Close'] = df['CLOSE'].shift(1)\n",
        "else:\n",
        "    print(\"Cannot add 'Prev_Close' as 'CLOSE' column is missing.\")\n",
        "    # Handle the missing column case - potentially stop here or use a fallback\n",
        "\n",
        "# Check the shape of the DataFrame after adding 'Prev_Close'\n",
        "print(\"\\nShape of DataFrame after adding Prev_Close (before dropping NaNs):\", df.shape)\n",
        "\n",
        "# Add checks for the number of NaN values in relevant columns\n",
        "print(\"\\nNaN counts before dropping NaNs:\")\n",
        "print(df[['CLOSE', 'Prev_Close']].isnull().sum())\n",
        "\n",
        "# Drop rows with NaN values - this is the suspected cause of the empty DataFrame\n",
        "# Let's drop NaNs only in the columns we plan to use for the model\n",
        "if 'Prev_Close' in df.columns and 'CLOSE' in df.columns:\n",
        "     df = df.dropna(subset=['Prev_Close', 'CLOSE'])\n",
        "else:\n",
        "    print(\"Cannot drop NaNs on 'Prev_Close' or 'CLOSE' as one or both columns are missing.\")\n",
        "    # Handle this case\n",
        "\n",
        "# Check the shape of the DataFrame after dropping NaNs\n",
        "print(\"\\nDataFrame shape after dropping NaNs:\", df.shape)\n",
        "print(\"\\nFirst few rows after dropping NaNs:\")\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# Proceed with splitting only if the DataFrame is not empty\n",
        "if not df.empty:\n",
        "    X = df[['Prev_Close']]\n",
        "    y = df['CLOSE']\n",
        "\n",
        "    print(\"\\nDataFrame after adding Prev_Close and dropping NaNs:\")\n",
        "    print(df.head())\n",
        "    print(\"\\nShape of X:\", X.shape)\n",
        "    print(\"Shape of y:\", y.shape)\n",
        "\n",
        "    # Add train-test split\n",
        "    # Split the data into training and testing sets\n",
        "    # This part was already present in your code, just ensuring it runs only if df is not empty\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # You can adjust test_size and random_state as needed\n",
        "\n",
        "    print(\"\\nShape of X_train:\", X_train.shape)\n",
        "    print(\"Shape of y_train:\", y_train.shape)\n",
        "    print(\"Shape of X_test:\", X_test.shape)\n",
        "    print(\"Shape of y_test:\", y_test.shape)\n",
        "\n",
        "    # Cell 6: Build and train the Linear Regression model\n",
        "    model = LinearRegression()\n",
        "    # Now X_train and y_train are defined and should not be empty\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    print(\"\\nModel training complete.\")\n",
        "else:\n",
        "    print(\"\\nDataFrame is empty after dropping NaNs. Cannot perform train-test split or model training.\")\n",
        "    print(\"Please inspect your 'symbols_valid_meta.csv' file and the column renaming steps.\")\n",
        "\n",
        "# You can add code here to make predictions and evaluate the model using X_test and y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMdzDQ918onq",
        "outputId": "b6b8a6d3-a2bd-4e47-8cb0-f4cf73110787"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame shape before adding Prev_Close: (0, 13)\n",
            "Data types before adding Prev_Close:\n",
            " symbol        object\n",
            "exchange      object\n",
            "name          object\n",
            "sector        object\n",
            "industry      object\n",
            "col6          object\n",
            "col7          object\n",
            "OPEN          object\n",
            "HIGH          object\n",
            "LOW           object\n",
            "CLOSE         object\n",
            "VOLUME        object\n",
            "Prev_Close    object\n",
            "dtype: object\n",
            "\n",
            "First few rows before adding Prev_Close:\n",
            "Empty DataFrame\n",
            "Columns: [symbol, exchange, name, sector, industry, col6, col7, OPEN, HIGH, LOW, CLOSE, VOLUME, Prev_Close]\n",
            "Index: []\n",
            "\n",
            "Shape of DataFrame after adding Prev_Close (before dropping NaNs): (0, 13)\n",
            "\n",
            "NaN counts before dropping NaNs:\n",
            "CLOSE         0\n",
            "Prev_Close    0\n",
            "dtype: int64\n",
            "\n",
            "DataFrame shape after dropping NaNs: (0, 13)\n",
            "\n",
            "First few rows after dropping NaNs:\n",
            "Empty DataFrame\n",
            "Columns: [symbol, exchange, name, sector, industry, col6, col7, OPEN, HIGH, LOW, CLOSE, VOLUME, Prev_Close]\n",
            "Index: []\n",
            "\n",
            "DataFrame is empty after dropping NaNs. Cannot perform train-test split or model training.\n",
            "Please inspect your 'symbols_valid_meta.csv' file and the column renaming steps.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell with the error: Now 'CLOSE' should exist\n",
        "# Add a check for the existence of the 'CLOSE' column\n",
        "if 'CLOSE' not in df.columns:\n",
        "    print(\"Error: 'CLOSE' column not found in the DataFrame.\")\n",
        "    # You need to correct the column renaming step above based on your CSV content.\n",
        "    # For now, let's stop execution or handle this case appropriately.\n",
        "    # For demonstration, we'll proceed, but this is a critical issue.\n",
        "    # You might want to add sys.exit() or raise an error here in a real script.\n",
        "    pass # Allowing execution to continue for demonstration of the next steps\n",
        "\n",
        "# Check the shape and content of the DataFrame before adding 'Prev_Close'\n",
        "print(\"\\nDataFrame shape before adding Prev_Close:\", df.shape)\n",
        "print(\"Data types before adding Prev_Close:\\n\", df.dtypes)\n",
        "print(\"\\nFirst few rows before adding Prev_Close:\")\n",
        "print(df.head())\n",
        "\n",
        "# Add 'Prev_Close' column\n",
        "if 'CLOSE' in df.columns:\n",
        "    # Attempt to convert 'CLOSE' to numeric, coercing errors to NaN\n",
        "    # Diagnostic: Print unique values and count of NaNs in 'CLOSE' before conversion\n",
        "    print(\"\\nUnique values in 'CLOSE' column before conversion (first 20):\")\n",
        "    print(df['CLOSE'].unique()[:20]) # Print first 20 unique values to inspect\n",
        "    print(f\"\\nInitial NaN count in 'CLOSE' column: {df['CLOSE'].isnull().sum()}\")\n",
        "\n",
        "    df['CLOSE'] = pd.to_numeric(df['CLOSE'], errors='coerce')\n",
        "\n",
        "    # Diagnostic: Print unique values and count of NaNs in 'CLOSE' after conversion\n",
        "    print(\"\\nUnique values in 'CLOSE' column after conversion (first 20):\")\n",
        "    print(df['CLOSE'].unique()[:20]) # Print first 20 unique values to inspect\n",
        "    print(f\"\\nNaN count in 'CLOSE' column after numeric conversion: {df['CLOSE'].isnull().sum()}\")\n",
        "\n",
        "\n",
        "    df['Prev_Close'] = df['CLOSE'].shift(1)\n",
        "\n",
        "else:\n",
        "    print(\"Cannot add 'Prev_Close' as 'CLOSE' column is missing.\")\n",
        "    # Handle the missing column case - potentially stop here or use a fallback\n",
        "\n",
        "# Check the shape of the DataFrame after adding 'Prev_Close'\n",
        "print(\"\\nShape of DataFrame after adding Prev_Close (before dropping NaNs):\", df.shape)\n",
        "\n",
        "# Add checks for the number of NaN values in relevant columns\n",
        "print(\"\\nNaN counts before dropping NaNs:\")\n",
        "print(df[['CLOSE', 'Prev_Close']].isnull().sum())\n",
        "\n",
        "# Diagnostic: Print the rows that will be dropped\n",
        "# This requires creating a boolean mask for rows with NaNs in the relevant subset\n",
        "if 'Prev_Close' in df.columns and 'CLOSE' in df.columns:\n",
        "    rows_with_nan = df[df[['Prev_Close', 'CLOSE']].isnull().any(axis=1)]\n",
        "    print(f\"\\nNumber of rows that will be dropped due to NaNs in 'Prev_Close' or 'CLOSE': {len(rows_with_nan)}\")\n",
        "    if len(rows_with_nan) > 0 and len(rows_with_nan) < 10: # Print a few if not too many\n",
        "        print(\"Example rows that will be dropped:\")\n",
        "        print(rows_with_nan)\n",
        "    elif len(rows_with_nan) >= 10:\n",
        "        print(\"First 10 example rows that will be dropped:\")\n",
        "        print(rows_with_nan.head(10))\n",
        "else:\n",
        "     print(\"\\nSkipping NaN row inspection as 'Prev_Close' or 'CLOSE' are missing.\")\n",
        "\n",
        "\n",
        "# Drop rows with NaN values - this is the suspected cause of the empty DataFrame\n",
        "# Let's drop NaNs only in the columns we plan to use for the model\n",
        "if 'Prev_Close' in df.columns and 'CLOSE' in df.columns:\n",
        "     df = df.dropna(subset=['Prev_Close', 'CLOSE'])\n",
        "else:\n",
        "    print(\"Cannot drop NaNs on 'Prev_Close' or 'CLOSE' as one or both columns are missing.\")\n",
        "    # Handle this case\n",
        "\n",
        "# Check the shape of the DataFrame after dropping NaNs\n",
        "print(\"\\nDataFrame shape after dropping NaNs:\", df.shape)\n",
        "print(\"\\nFirst few rows after dropping NaNs:\")\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# Proceed with splitting only if the DataFrame is not empty\n",
        "if not df.empty:\n",
        "    X = df[['Prev_Close']]\n",
        "    y = df['CLOSE']\n",
        "\n",
        "    print(\"\\nDataFrame after adding Prev_Close and dropping NaNs:\")\n",
        "    print(df.head())\n",
        "    print(\"\\nShape of X:\", X.shape)\n",
        "    print(\"Shape of y:\", y.shape)\n",
        "\n",
        "    # Add train-test split\n",
        "    # Split the data into training and testing sets\n",
        "    # This part was already present in your code, just ensuring it runs only if df is not empty\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # You can adjust test_size and random_state as needed\n",
        "\n",
        "    print(\"\\nShape of X_train:\", X_train.shape)\n",
        "    print(\"Shape of y_train:\", y_train.shape)\n",
        "    print(\"Shape of X_test:\", X_test.shape)\n",
        "    print(\"Shape of y_test:\", y_test.shape)\n",
        "\n",
        "    # Cell 6: Build and train the Linear Regression model\n",
        "    model = LinearRegression()\n",
        "    # Now X_train and y_train are defined and should not be empty\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    print(\"\\nModel training complete.\")\n",
        "else:\n",
        "    print(\"\\nDataFrame is empty after dropping NaNs. Cannot perform train-test split or model training.\")\n",
        "    print(\"Please inspect your 'symbols_valid_meta.csv' file and the column renaming steps.\")\n",
        "\n",
        "# You can add code here to make predictions and evaluate the model using X_test and y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEy5osYO9Xoi",
        "outputId": "ec0252f9-6d0f-41ec-a694-594c17340aaa"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame shape before adding Prev_Close: (0, 13)\n",
            "Data types before adding Prev_Close:\n",
            " symbol         object\n",
            "exchange       object\n",
            "name           object\n",
            "sector         object\n",
            "industry       object\n",
            "col6           object\n",
            "col7           object\n",
            "OPEN           object\n",
            "HIGH           object\n",
            "LOW            object\n",
            "CLOSE           int64\n",
            "VOLUME         object\n",
            "Prev_Close    float64\n",
            "dtype: object\n",
            "\n",
            "First few rows before adding Prev_Close:\n",
            "Empty DataFrame\n",
            "Columns: [symbol, exchange, name, sector, industry, col6, col7, OPEN, HIGH, LOW, CLOSE, VOLUME, Prev_Close]\n",
            "Index: []\n",
            "\n",
            "Unique values in 'CLOSE' column before conversion (first 20):\n",
            "[]\n",
            "\n",
            "Initial NaN count in 'CLOSE' column: 0\n",
            "\n",
            "Unique values in 'CLOSE' column after conversion (first 20):\n",
            "[]\n",
            "\n",
            "NaN count in 'CLOSE' column after numeric conversion: 0\n",
            "\n",
            "Shape of DataFrame after adding Prev_Close (before dropping NaNs): (0, 13)\n",
            "\n",
            "NaN counts before dropping NaNs:\n",
            "CLOSE         0\n",
            "Prev_Close    0\n",
            "dtype: int64\n",
            "\n",
            "Number of rows that will be dropped due to NaNs in 'Prev_Close' or 'CLOSE': 0\n",
            "\n",
            "DataFrame shape after dropping NaNs: (0, 13)\n",
            "\n",
            "First few rows after dropping NaNs:\n",
            "Empty DataFrame\n",
            "Columns: [symbol, exchange, name, sector, industry, col6, col7, OPEN, HIGH, LOW, CLOSE, VOLUME, Prev_Close]\n",
            "Index: []\n",
            "\n",
            "DataFrame is empty after dropping NaNs. Cannot perform train-test split or model training.\n",
            "Please inspect your 'symbols_valid_meta.csv' file and the column renaming steps.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell with the error: Now 'CLOSE' should exist\n",
        "# Add a check for the existence of the 'CLOSE' column\n",
        "if 'CLOSE' not in df.columns:\n",
        "    print(\"Error: 'CLOSE' column not found in the DataFrame.\")\n",
        "    # You need to correct the column renaming step above based on your CSV content.\n",
        "    # For now, let's stop execution or handle this case appropriately.\n",
        "    # For demonstration, we'll proceed, but this is a critical issue.\n",
        "    # You might want to add sys.exit() or raise an error here in a real script.\n",
        "    pass # Allowing execution to continue for demonstration of the next steps\n",
        "\n",
        "# Check the shape and content of the DataFrame before adding 'Prev_Close'\n",
        "print(\"\\nDataFrame shape before adding Prev_Close:\", df.shape)\n",
        "print(\"Data types before adding Prev_Close:\\n\", df.dtypes)\n",
        "print(\"\\nFirst few rows before adding Prev_Close:\")\n",
        "print(df.head())\n",
        "\n",
        "# Add 'Prev_Close' column\n",
        "if 'CLOSE' in df.columns:\n",
        "    # Attempt to convert 'CLOSE' to numeric, coercing errors to NaN\n",
        "    # Diagnostic: Print unique values and count of NaNs in 'CLOSE' before conversion\n",
        "    print(\"\\nUnique values in 'CLOSE' column before conversion (first 20):\")\n",
        "    # Ensure the column is not entirely NaN before attempting to print unique values\n",
        "    if not df['CLOSE'].isnull().all():\n",
        "        print(df['CLOSE'].unique()[:20]) # Print first 20 unique values to inspect\n",
        "    else:\n",
        "        print(\"CLOSE column is all NaNs before conversion.\")\n",
        "\n",
        "    print(f\"\\nInitial NaN count in 'CLOSE' column: {df['CLOSE'].isnull().sum()}\")\n",
        "\n",
        "    df['CLOSE'] = pd.to_numeric(df['CLOSE'], errors='coerce')\n",
        "\n",
        "    # Diagnostic: Print unique values and count of NaNs in 'CLOSE' after conversion\n",
        "    print(\"\\nUnique values in 'CLOSE' column after conversion (first 20):\")\n",
        "    # Ensure the column is not entirely NaN after conversion before attempting to print unique values\n",
        "    if not df['CLOSE'].isnull().all():\n",
        "        print(df['CLOSE'].unique()[:20]) # Print first 20 unique values to inspect\n",
        "    else:\n",
        "        print(\"CLOSE column is all NaNs after conversion.\")\n",
        "\n",
        "    print(f\"\\nNaN count in 'CLOSE' column after numeric conversion: {df['CLOSE'].isnull().sum()}\")\n",
        "\n",
        "\n",
        "    df['Prev_Close'] = df['CLOSE'].shift(1)\n",
        "\n",
        "else:\n",
        "    print(\"Cannot add 'Prev_Close' as 'CLOSE' column is missing.\")\n",
        "    # Handle the missing column case - potentially stop here or use a fallback\n",
        "\n",
        "# Check the shape of the DataFrame after adding 'Prev_Close'\n",
        "print(\"\\nShape of DataFrame after adding Prev_Close (before dropping NaNs):\", df.shape)\n",
        "\n",
        "# Add checks for the number of NaN values in relevant columns\n",
        "if 'Prev_Close' in df.columns and 'CLOSE' in df.columns:\n",
        "    print(\"\\nNaN counts before dropping NaNs:\")\n",
        "    print(df[['CLOSE', 'Prev_Close']].isnull().sum())\n",
        "else:\n",
        "     print(\"\\nSkipping NaN count check as 'Prev_Close' or 'CLOSE' are missing.\")\n",
        "\n",
        "\n",
        "# Diagnostic: Print the rows that will be dropped\n",
        "# This requires creating a boolean mask for rows with NaNs in the relevant subset\n",
        "if 'Prev_Close' in df.columns and 'CLOSE' in df.columns:\n",
        "    rows_with_nan = df[df[['Prev_Close', 'CLOSE']].isnull().any(axis=1)]\n",
        "    print(f\"\\nNumber of rows that will be dropped due to NaNs in 'Prev_Close' or 'CLOSE': {len(rows_with_nan)}\")\n",
        "    if len(rows_with_nan) > 0 and len(rows_with_nan) < 10: # Print a few if not too many\n",
        "        print(\"Example rows that will be dropped:\")\n",
        "        display(rows_with_nan) # Use display for better DataFrame rendering in notebook\n",
        "    elif len(rows_with_nan) >= 10:\n",
        "        print(\"First 10 example rows that will be dropped:\")\n",
        "        display(rows_with_nan.head(10)) # Use display for better DataFrame rendering in notebook\n",
        "else:\n",
        "     print(\"\\nSkipping NaN row inspection as 'Prev_Close' or 'CLOSE' are missing.\")\n",
        "\n",
        "\n",
        "# Drop rows with NaN values - this is the suspected cause of the empty DataFrame\n",
        "# Let's drop NaNs only in the columns we plan to use for the model\n",
        "original_rows = len(df)\n",
        "if 'Prev_Close' in df.columns and 'CLOSE' in df.columns:\n",
        "     df = df.dropna(subset=['Prev_Close', 'CLOSE'])\n",
        "     print(f\"\\nDropped {original_rows - len(df)} rows due to NaNs in 'Prev_Close' or 'CLOSE'.\")\n",
        "else:\n",
        "    print(\"Cannot drop NaNs on 'Prev_Close' or 'CLOSE' as one or both columns are missing.\")\n",
        "    # Handle this case\n",
        "\n",
        "# Check the shape of the DataFrame after dropping NaNs\n",
        "print(\"\\nDataFrame shape after dropping NaNs:\", df.shape)\n",
        "print(\"\\nFirst few rows after dropping NaNs:\")\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# Proceed with splitting only if the DataFrame is not empty\n",
        "if not df.empty:\n",
        "    X = df[['Prev_Close']]\n",
        "    y = df['CLOSE']\n",
        "\n",
        "    print(\"\\nDataFrame after adding Prev_Close and dropping NaNs:\")\n",
        "    print(df.head())\n",
        "    print(\"\\nShape of X:\", X.shape)\n",
        "    print(\"Shape of y:\", y.shape)\n",
        "\n",
        "    # Add train-test split\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # You can adjust test_size and random_state as needed\n",
        "\n",
        "    print(\"\\nShape of X_train:\", X_train.shape)\n",
        "    print(\"Shape of y_train:\", y_train.shape)\n",
        "    print(\"Shape of X_test:\", X_test.shape)\n",
        "    print(\"Shape of y_test:\", y_test.shape)\n",
        "\n",
        "    # Cell 6: Build and train the Linear Regression model\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    print(\"\\nModel training complete.\")\n",
        "\n",
        "    # Cell 8: Evaluate the model - MOVED INSIDE THIS BLOCK\n",
        "    print(\"\\nEvaluating the model...\")\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "    print(f\"Mean Absolute Error: {mae:.2f}\")\n",
        "    print(f\"R^2 Score: {r2:.2f}\")\n",
        "\n",
        "else:\n",
        "    print(\"\\nDataFrame is empty after dropping NaNs. Cannot perform train-test split, model training, or evaluation.\")\n",
        "    print(\"Please inspect your 'symbols_valid_meta.csv' file and the column renaming steps to ensure valid data exists after cleaning.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTubJ0Aa9wF4",
        "outputId": "d4b99c4e-de7c-4358-da31-e3efe96951e4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame shape before adding Prev_Close: (0, 13)\n",
            "Data types before adding Prev_Close:\n",
            " symbol         object\n",
            "exchange       object\n",
            "name           object\n",
            "sector         object\n",
            "industry       object\n",
            "col6           object\n",
            "col7           object\n",
            "OPEN           object\n",
            "HIGH           object\n",
            "LOW            object\n",
            "CLOSE           int64\n",
            "VOLUME         object\n",
            "Prev_Close    float64\n",
            "dtype: object\n",
            "\n",
            "First few rows before adding Prev_Close:\n",
            "Empty DataFrame\n",
            "Columns: [symbol, exchange, name, sector, industry, col6, col7, OPEN, HIGH, LOW, CLOSE, VOLUME, Prev_Close]\n",
            "Index: []\n",
            "\n",
            "Unique values in 'CLOSE' column before conversion (first 20):\n",
            "CLOSE column is all NaNs before conversion.\n",
            "\n",
            "Initial NaN count in 'CLOSE' column: 0\n",
            "\n",
            "Unique values in 'CLOSE' column after conversion (first 20):\n",
            "CLOSE column is all NaNs after conversion.\n",
            "\n",
            "NaN count in 'CLOSE' column after numeric conversion: 0\n",
            "\n",
            "Shape of DataFrame after adding Prev_Close (before dropping NaNs): (0, 13)\n",
            "\n",
            "NaN counts before dropping NaNs:\n",
            "CLOSE         0\n",
            "Prev_Close    0\n",
            "dtype: int64\n",
            "\n",
            "Number of rows that will be dropped due to NaNs in 'Prev_Close' or 'CLOSE': 0\n",
            "\n",
            "Dropped 0 rows due to NaNs in 'Prev_Close' or 'CLOSE'.\n",
            "\n",
            "DataFrame shape after dropping NaNs: (0, 13)\n",
            "\n",
            "First few rows after dropping NaNs:\n",
            "Empty DataFrame\n",
            "Columns: [symbol, exchange, name, sector, industry, col6, col7, OPEN, HIGH, LOW, CLOSE, VOLUME, Prev_Close]\n",
            "Index: []\n",
            "\n",
            "DataFrame is empty after dropping NaNs. Cannot perform train-test split, model training, or evaluation.\n",
            "Please inspect your 'symbols_valid_meta.csv' file and the column renaming steps to ensure valid data exists after cleaning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "if 'CLOSE' not in df.columns:\n",
        "    print(\"Error: 'CLOSE' column not found in the DataFrame.\")\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "print(\"\\nDataFrame shape before adding Prev_Close:\", df.shape)\n",
        "print(\"Data types before adding Prev_Close:\\n\", df.dtypes)\n",
        "print(\"\\nFirst few rows before adding Prev_Close:\")\n",
        "print(df.head())\n",
        "\n",
        "# Add 'Prev_Close' column\n",
        "if 'CLOSE' in df.columns:\n",
        "\n",
        "    print(\"\\nUnique values in 'CLOSE' column before conversion (first 20):\")\n",
        "    # Ensure the column is not entirely NaN before attempting to print unique values\n",
        "    if not df['CLOSE'].isnull().all():\n",
        "        print(df['CLOSE'].unique()[:20]) # Print first 20 unique values to inspect\n",
        "    else:\n",
        "        print(\"CLOSE column is all NaNs before conversion.\")\n",
        "\n",
        "    print(f\"\\nInitial NaN count in 'CLOSE' column: {df['CLOSE'].isnull().sum()}\")\n",
        "\n",
        "    df['CLOSE'] = pd.to_numeric(df['CLOSE'], errors='coerce')\n",
        "\n",
        "    # Diagnostic: Print unique values and count of NaNs in 'CLOSE' after conversion\n",
        "    print(\"\\nUnique values in 'CLOSE' column after conversion (first 20):\")\n",
        "    # Ensure the column is not entirely NaN after conversion before attempting to print unique values\n",
        "    if not df['CLOSE'].isnull().all():\n",
        "        print(df['CLOSE'].unique()[:20]) # Print first 20 unique values to inspect\n",
        "    else:\n",
        "        print(\"CLOSE column is all NaNs after conversion.\")\n",
        "\n",
        "    print(f\"\\nNaN count in 'CLOSE' column after numeric conversion: {df['CLOSE'].isnull().sum()}\")\n",
        "\n",
        "\n",
        "    df['Prev_Close'] = df['CLOSE'].shift(1)\n",
        "\n",
        "else:\n",
        "    print(\"Cannot add 'Prev_Close' as 'CLOSE' column is missing.\")\n",
        "    # Handle the missing column case - potentially stop here or use a fallback\n",
        "\n",
        "# Check the shape of the DataFrame after adding 'Prev_Close'\n",
        "print(\"\\nShape of DataFrame after adding Prev_Close (before dropping NaNs):\", df.shape)\n",
        "\n",
        "# Add checks for the number of NaN values in relevant columns\n",
        "if 'Prev_Close' in df.columns and 'CLOSE' in df.columns:\n",
        "    print(\"\\nNaN counts before dropping NaNs:\")\n",
        "    print(df[['CLOSE', 'Prev_Close']].isnull().sum())\n",
        "else:\n",
        "     print(\"\\nSkipping NaN count check as 'Prev_Close' or 'CLOSE' are missing.\")\n",
        "\n",
        "\n",
        "# Diagnostic: Print the rows that will be dropped\n",
        "# This requires creating a boolean mask for rows with NaNs in the relevant subset\n",
        "if 'Prev_Close' in df.columns and 'CLOSE' in df.columns:\n",
        "    rows_with_nan = df[df[['Prev_Close', 'CLOSE']].isnull().any(axis=1)]\n",
        "    print(f\"\\nNumber of rows that will be dropped due to NaNs in 'Prev_Close' or 'CLOSE': {len(rows_with_nan)}\")\n",
        "    if len(rows_with_nan) > 0 and len(rows_with_nan) < 10: # Print a few if not too many\n",
        "        print(\"Example rows that will be dropped:\")\n",
        "        display(rows_with_nan) # Use display for better DataFrame rendering in notebook\n",
        "    elif len(rows_with_nan) >= 10:\n",
        "        print(\"First 10 example rows that will be dropped:\")\n",
        "        display(rows_with_nan.head(10)) # Use display for better DataFrame rendering in notebook\n",
        "else:\n",
        "     print(\"\\nSkipping NaN row inspection as 'Prev_Close' or 'CLOSE' are missing.\")\n",
        "\n",
        "\n",
        "# Drop rows with NaN values - this is the suspected cause of the empty DataFrame\n",
        "# Let's drop NaNs only in the columns we plan to use for the model\n",
        "original_rows = len(df)\n",
        "if 'Prev_Close' in df.columns and 'CLOSE' in df.columns:\n",
        "     df = df.dropna(subset=['Prev_Close', 'CLOSE'])\n",
        "     print(f\"\\nDropped {original_rows - len(df)} rows due to NaNs in 'Prev_Close' or 'CLOSE'.\")\n",
        "else:\n",
        "    print(\"Cannot drop NaNs on 'Prev_Close' or 'CLOSE' as one or both columns are missing.\")\n",
        "    # Handle this case\n",
        "\n",
        "# Check the shape of the DataFrame after dropping NaNs\n",
        "print(\"\\nDataFrame shape after dropping NaNs:\", df.shape)\n",
        "print(\"\\nFirst few rows after dropping NaNs:\")\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# Proceed with splitting only if the DataFrame is not empty\n",
        "if not df.empty:\n",
        "    X = df[['Prev_Close']]\n",
        "    y = df['CLOSE']\n",
        "\n",
        "    print(\"\\nDataFrame after adding Prev_Close and dropping NaNs:\")\n",
        "    print(df.head())\n",
        "    print(\"\\nShape of X:\", X.shape)\n",
        "    print(\"Shape of y:\", y.shape)\n",
        "\n",
        "    # Add train-test split\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # You can adjust test_size and random_state as needed\n",
        "\n",
        "    print(\"\\nShape of X_train:\", X_train.shape)\n",
        "    print(\"Shape of y_train:\", y_train.shape)\n",
        "    print(\"Shape of X_test:\", X_test.shape)\n",
        "    print(\"Shape of y_test:\", y_test.shape)\n",
        "\n",
        "    # Cell 6: Build and train the Linear Regression model\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    print(\"\\nModel training complete.\")\n",
        "\n",
        "    # Cell 8: Evaluate the model - MOVED INSIDE THIS BLOCK\n",
        "    print(\"\\nEvaluating the model...\")\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"Mean Squared Error: {mse:.2f}\")\n",
        "    print(f\"Mean Absolute Error: {mae:.2f}\")\n",
        "    print(f\"R^2 Score: {r2:.2f}\")\n",
        "\n",
        "\n",
        "    print(\"\\nGenerating plot...\")\n",
        "    plt.figure(figsize=(14,6))\n",
        "    plt.plot(y_test.values, label='Actual Close Price', color='b')\n",
        "    plt.plot(y_pred, label='Predicted Close Price', color='r')\n",
        "    plt.title('Stock Price Prediction: Actual vs Predicted')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Stock Close Price')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"\\nDataFrame is empty after dropping NaNs. Cannot perform train-test split, model training, evaluation, or plotting.\")\n",
        "    print(\"Please inspect your 'symbols_valid_meta.csv' file and the column renaming steps to ensure valid data exists after cleaning.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsdqwSM397tS",
        "outputId": "33feb1e8-35fb-47c2-e3cc-6ec28c36cfdc"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DataFrame shape before adding Prev_Close: (0, 13)\n",
            "Data types before adding Prev_Close:\n",
            " symbol         object\n",
            "exchange       object\n",
            "name           object\n",
            "sector         object\n",
            "industry       object\n",
            "col6           object\n",
            "col7           object\n",
            "OPEN           object\n",
            "HIGH           object\n",
            "LOW            object\n",
            "CLOSE           int64\n",
            "VOLUME         object\n",
            "Prev_Close    float64\n",
            "dtype: object\n",
            "\n",
            "First few rows before adding Prev_Close:\n",
            "Empty DataFrame\n",
            "Columns: [symbol, exchange, name, sector, industry, col6, col7, OPEN, HIGH, LOW, CLOSE, VOLUME, Prev_Close]\n",
            "Index: []\n",
            "\n",
            "Unique values in 'CLOSE' column before conversion (first 20):\n",
            "CLOSE column is all NaNs before conversion.\n",
            "\n",
            "Initial NaN count in 'CLOSE' column: 0\n",
            "\n",
            "Unique values in 'CLOSE' column after conversion (first 20):\n",
            "CLOSE column is all NaNs after conversion.\n",
            "\n",
            "NaN count in 'CLOSE' column after numeric conversion: 0\n",
            "\n",
            "Shape of DataFrame after adding Prev_Close (before dropping NaNs): (0, 13)\n",
            "\n",
            "NaN counts before dropping NaNs:\n",
            "CLOSE         0\n",
            "Prev_Close    0\n",
            "dtype: int64\n",
            "\n",
            "Number of rows that will be dropped due to NaNs in 'Prev_Close' or 'CLOSE': 0\n",
            "\n",
            "Dropped 0 rows due to NaNs in 'Prev_Close' or 'CLOSE'.\n",
            "\n",
            "DataFrame shape after dropping NaNs: (0, 13)\n",
            "\n",
            "First few rows after dropping NaNs:\n",
            "Empty DataFrame\n",
            "Columns: [symbol, exchange, name, sector, industry, col6, col7, OPEN, HIGH, LOW, CLOSE, VOLUME, Prev_Close]\n",
            "Index: []\n",
            "\n",
            "DataFrame is empty after dropping NaNs. Cannot perform train-test split, model training, evaluation, or plotting.\n",
            "Please inspect your 'symbols_valid_meta.csv' file and the column renaming steps to ensure valid data exists after cleaning.\n"
          ]
        }
      ]
    }
  ]
}